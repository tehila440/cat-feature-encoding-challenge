{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(\"../input/cat-in-the-dat-ii/sample_submission.csv\")\n",
    "test = pd.read_csv(\"../input/cat-in-the-dat-ii/test.csv\",index_col = 'id')\n",
    "train = pd.read_csv(\"../input/cat-in-the-dat-ii/train.csv\",index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "#remove rows with missing target\n",
    "train.dropna(axis=0, subset=['target'], inplace=True)\n",
    "train_y=train.target\n",
    "train.drop(['target'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns.difference([\"id\"]):\n",
    "    train_vals = set(train[col].dropna().unique())\n",
    "    test_vals = set(test[col].dropna().unique())\n",
    "\n",
    "    xor_cat_vals = train_vals ^ test_vals\n",
    "    if xor_cat_vals:\n",
    "        print(f\"Replacing {len(xor_cat_vals)} values in {col}, {xor_cat_vals}\")\n",
    "        train.loc[train[col].isin(xor_cat_vals), col] = \"xor\"\n",
    "        test.loc[test[col].isin(xor_cat_vals), col] = \"xor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_cat_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Variable Description'''\n",
    "def description(df):\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Name'] = summary['index']\n",
    "    summary = summary[['Name','dtypes']]\n",
    "    summary['Missing'] = df.isnull().sum().values\n",
    "    summary['PercMissing'] = df.isnull().sum().values / df.isnull().count().values\n",
    "    summary['Uniques'] = df.nunique().values\n",
    "    summary['First Value'] = df.iloc[0].values\n",
    "    summary['Second Value'] = df.iloc[1].values\n",
    "    summary['Third Value'] = df.iloc[2].values\n",
    "    return summary\n",
    "print('**Variable Description of  train Data:**')\n",
    "description(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in mode for all NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train.columns\n",
    "for c in columns:\n",
    "    train[c].fillna(train[c].mode()[0],inplace=True)\n",
    "    test[c].fillna(test[c].mode()[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# piv = train.pivot_table(index='ord_0', values='target')\n",
    "# piv.plot.bar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_ord = ['bin_3','bin_4','ord_1', 'ord_2']\n",
    "for col in columns_to_ord:\n",
    "    print('{}'.format(col), train[col].unique(),'\\n' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bin_3 = {'T':1, 'F':0}\n",
    "dict_bin_4 = {'Y': 1, 'N':0}\n",
    "dict_ord_1 = {'Novice':1,'Contributor':2,'Expert':3,'Master':4,'Grandmaster':5, }\n",
    "dict_ord_2 = {'Freezing':1,'Cold':2,'Warm':3,'Hot':4,'Boiling Hot':5,'Lava Hot':6}\n",
    "# dict_ord_3 = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':6, 'g':7, 'h':8, 'i':9, 'j':10, 'k':11,\n",
    "#               'l':12, 'm':13,'n':14, 'o':15}\n",
    "# dict_ord_4 = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'H':8, 'I':9, 'J':10,'K':11,\n",
    "#               'L':12, 'M':13,'N':14, 'O':15, 'P':16, 'Q':17, 'R':18, 'S':19, 'T':20, 'U':21,\n",
    "#               'V':21, 'W':22, 'X':24, 'Y':25, 'Z':26}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list=[dict_bin_3, dict_bin_4,dict_ord_1,dict_ord_2]\n",
    "cols = ['bin_3','bin_4','ord_1', 'ord_2']\n",
    "for i in range(0,len(cols)):\n",
    "    col = cols[i]\n",
    "    d = dict_list[i]\n",
    "    train[col]=train[col].replace(d)\n",
    "    test[col]=test[col].replace(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_ord5 = {key:value for value,key in enumerate(sorted(train.ord_5.unique()))} \n",
    "# train.ord_5 = train.ord_5.map(map_ord5)\n",
    "# test.ord_5 = test.ord_5.map(map_ord5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining object columns are not ordinal so we will use target encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.month=train.month.apply(lambda x: str(x))\n",
    "train.day=train.day.apply(lambda x: str(x))\n",
    "test.month=test.month.apply(lambda x: str(x))\n",
    "test.day=test.day.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat_to_encode=train.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat_to_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "smoothing = 0.2\n",
    "oof = pd.DataFrame([])\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "for tr_idx, oof_idx in StratifiedKFold(n_splits=5, random_state=2020, shuffle=True).split(train, train_y):\n",
    "    ce_target_encoder = ce.TargetEncoder(cols = cat_feat_to_encode, smoothing=smoothing)\n",
    "    ce_target_encoder.fit(train.iloc[tr_idx, :], train_y.iloc[tr_idx])\n",
    "    oof = oof.append(ce_target_encoder.transform(train.iloc[oof_idx, :]), ignore_index=False)\n",
    "ce_target_encoder = ce.TargetEncoder(cols = cat_feat_to_encode, smoothing=smoothing)\n",
    "ce_target_encoder.fit(train, train_y);  train = oof.sort_index(); test = ce_target_encoder.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "XGB = XGBClassifier(n_estimators = 500, learning_rate=0.01, objective='binary:logistic',\n",
    "                         tree_method = 'hist', max_depth = 5) \n",
    "\n",
    "#lr = LogisticRegression(solver='liblinear', random_state=0)\n",
    "scores_xgb = cross_val_score(XGB, train, train_y,\n",
    "                               cv=5,\n",
    "                               scoring='roc_auc')\n",
    "print(scores_xgb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model_lr = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "scores_lr = cross_val_score(model_lr, train, train_y,\n",
    "                               cv=5,\n",
    "                               scoring='roc_auc')\n",
    "print(scores_lr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators = 100, random_state=0)\n",
    "# scores_rf = cross_val_score(model_rf, train, train_y,\n",
    "#                                cv=5,\n",
    "#                                scoring='roc_auc')\n",
    "# print(scores_rf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(train, train_y)\n",
    "pred_rf=model_rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.fit(train, train_y)\n",
    "pred_lr=model_lr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame({'Id':test.index, 'Target':pred_rf})\n",
    "output.to_csv('submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target']=train_y\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=train.corr()\n",
    "import seaborn as sns\n",
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
